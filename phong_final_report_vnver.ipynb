{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phong_Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Hệ thống tự động nhận diện trạng thái bãi đỗ xe</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lý thuyết\n",
    "Hệ thống được hình thành để phân loại các lot đậu xe thành 2 loại là trống hoặc đã có xe đỗ vào. Hệ thống này đặc biệt tối ưu với các bãi đỗ xe có camera ở các cột đèn hay có tầm nhìn thoáng và rộng. Hệ thống sử dụng sự kết hợp của toán tử Laplace để xác định viền ảnh, Haar classifier để nhận dạng đối tượng và theo dõi chuyển động để phân biệt giữa chỗ chưa đã có và chưa có xe đậu. Theo dõi chuyển động được thiết kế bằng việc sử dụng kĩ thuật background substraction (tách cảnh nền), contours (được hiểu đơn giản là một đường cong liên kết toàn bộ các điểm liên tục (dọc theo đường biên) mà có cùng màu sắc hoặc giá trị cường độ.) và Morphological operations cũng được sử dụng. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hướng tiếp cận\n",
    "Haar classifier đã được cân nhắc so sánh với SVM và HOG. Mặc dù HOG kết hợp với SVM sẽ mang lại độ chính xác cao hơn nếu so sánh với Haar nhưng việc các yêu cầu về quá trình xử lý của Haar là ít hơn rất nhiều so với HOG. Cuối cùng, Haar được lựa chọn để áp dụng vào hệ thống lần này.Chức năng phát hiện người qua đường của HOG được cài đặt sẵn trong opencv2 cũng được sử dụng nhưng nó được tắt đi vì nó sẽ làm chậm tốc độ xử lý của hệ thống. Để tăng độ chính xác trong việc phân loại các lot đỗ xe, toán tử Laplace được sử dụng. Threshold sẽ được thiết lập nơi khả năng hiện diện của xe là tối đa. Về cơ bản, các khu vực đậu xe xác định bằng tay và threshold được xác định bằng cách tính toán độ lớn của các cạnh bên trong chúng. Với một chiếc xe thì nó sẽ có một số cạnh đáng kể, trong khi chỗ đậu xe trống gần như là mịn màng. Đây là thực tế đằng sau việc sử dụng toán tử Laplace. Nếu khả năng hiện diện của một chiếc xe vượt quá threshold thì thuật toán phân loại ngay lập tức được áp dụng để phát hiện liệu nó có phải là một chiếc xe hay không. Bất cứ khi nào một sự thay đổi threshold được tìm thấy, thuật toán phân loại sẽ được gọi là để kiểm tra liệu đó là một chiếc xe hay không. Nếu được xác định là một chiếc xe thì nó sẽ được đánh dấu và quan sát chuyển động. Bất cứ khi nào có một chuyển động tại một điểm, thuật toán phân loại sẽ lại được gọi là để xác định sự hiện diện của xe. Vì vậy hệ thống đề xuất một sự kết hợp của phát hiện, theo dõi và phân loại để đạt được bãi đậu xe hiệu quả.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết quả\n",
    "Một chương trình đã được em sử dụng để tính toán độ chính xác của thuật toán phân loại trong việc phát hiện xe. Chương trình áp dụng thuật toán phân loại vào một số khung hình được em cắt ra từ video và từ đó tính toán được tỉ lệ phát hiện chính xác số xe trong từng khung hình. Tiếp đó, nó sẽ hiển thị giá trị trung bình tỉ lệ của tất cả các khung hình. Kết quả thu được như sau:\n",
    "\n",
    "* Classifier được train với: **1562 Positives and 1772 Negatives** (có thể kiểm tra bằng việc click vào file 'haarTraining.bat'. Có thể kiểm tra ở mục screenshots để xem quá trình training)\n",
    "* Số khung hình được sử dụng: **5**\n",
    "* Trung bình tỉ lệ chính xác:  **62.25%** (Xem phần tính toán bằng đoạn code được viết ở cuối cùng)\n",
    "\n",
    "\n",
    "Threshold được thay đổi và em nhận thấy rằng nó sẽ cho ra tỉ lệ chính xác nhật với giá trị là 2.7 (Vui lòng kiểm tra chương trình tính toán giá trị Threshold)\n",
    "\n",
    "\n",
    "Kết quả của thí nghiệm kiểm tra Threshold với tổng số xe là 120\n",
    "\n",
    "* Threshold = 1.5  Số xe không được phân loại = 54 \n",
    "\n",
    "* Threshold = 2.0  Số xe không được phân loại = 39 \n",
    "\n",
    "* Threshold = 2.8  Số xe không được phân loại = 19\n",
    "\n",
    "* Threshold = 3.0  Số xe không được phân loại = 24\n",
    "\n",
    "* Threshold = 3.5  Số xe không được phân loại = 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "1. Chương trình chính của hệ thống.\n",
    "2. Chương trình cho phép ta thấy độ nhạy của thuật toán áp dụng đối với đường cao tốc M6, một trong những đường cao tốc có lưu lượng xe lớn nhất thế giới.\n",
    "3. Chương trình cho phép ta xác định độ chính xác của thuật toán phân loại\n",
    "4. Chương trình cho phép ta xác định các lot đỗ xe trên video bằng tay và lưu chúng vào yaml file để phục vụ cho hệ thống.\n",
    "5. Chương trình giúp tính toán giá trị ước lượng của Threshold cho một video xác định."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-c5dd0a02c8be>:77: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  parking_data = yaml.load(stream)\n",
      "<ipython-input-8-c5dd0a02c8be>:56: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if cars == ():\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hướng dẫn: Escape key Nhấn Esc để thoát chương trình, lưu ý có thể ấn nhiều lần nếu lệnh không được thực hiện.\n",
    "Nhấn U để nhảy 500 frames và nhận J để nhảy 1000 frames.\n",
    "Các giá trị có thể chỉnh sửa được trong dictionary:\n",
    "1. show_ids: Bật hoặc tắt id cuẩ từng lot\n",
    "2. save_video: Lưu video được tạo ra từ chương trình\n",
    "3. text_overlay: Hiển thị đếm frame ở góc trên màn hình.\n",
    "4. motion_detection: Bật hoặc tắt motion detection\n",
    "5. pedestrian detection: Khiến cho chương trình chậm vì function HOG trong opencv\n",
    "6. min_area_motion_contour: Area cần nhỏ nhất cho motion\n",
    "7. start_frame: Bắt đầu từ frame nào\n",
    "8. park_laplacian_th: Thiết lập giá trị Threshold\n",
    "\"\"\"\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "fn = \"myCam.avi\" #3\n",
    "fn_yaml = \"phong_yml_01.yml\"\n",
    "fn_out =  \"phong_outputvideo_02.avi\"\n",
    "cascade_src = 'cars.xml'\n",
    "car_cascade = cv2.CascadeClassifier(cascade_src)\n",
    "global_str = \"Last change at: \"\n",
    "change_pos = 0.00\n",
    "dict =  {\n",
    "        'print_out':True,\n",
    "        'text_overlay': True,\n",
    "        'parking_overlay': True,\n",
    "        'parking_id_overlay': True,\n",
    "        'parking_detection': True,\n",
    "        'motion_detection': False,\n",
    "        'pedestrian_detection': False, # mất nhiều power\n",
    "        'min_area_motion_contour': 500, \n",
    "        'park_laplacian_th': 1.9, \n",
    "        'park_sec_to_wait': 1, #thời gian đợi để thay đổi trạng thái của region \n",
    "        'start_frame': 0, # Bắt đầu từ frame nào\n",
    "        'show_ids': True, # Hiển thị id cho từng lot\n",
    "        'classifier_used': True,\n",
    "        'save_video': False\n",
    "        }\n",
    "\n",
    "# Set từ video\n",
    "cap = cv2.VideoCapture(fn)\n",
    "video_info = {  'fps':    cap.get(cv2.CAP_PROP_FPS),\n",
    "                'width':  int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)*0.6),\n",
    "                'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)*0.6),\n",
    "                'fourcc': cap.get(cv2.CAP_PROP_FOURCC),\n",
    "                'num_of_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT))}\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, dict['start_frame']) # Nhảy đến frame được xác định trước\n",
    "\n",
    "def run_classifier(img, id):\n",
    "    cars = car_cascade.detectMultiScale(img, 1.1, 1)\n",
    "    if cars == ():\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# Định nghĩa codec và tạo VideoWriter object\n",
    "if dict['save_video']:\n",
    "    fourcc = cv2.VideoWriter_fourcc('X','V','I','D') # các lựa chọn: ('P','I','M','1'), ('D','I','V','X'), ('M','J','P','G'), ('X','V','I','D')\n",
    "    out = cv2.VideoWriter(fn_out, -1, 25.0,(video_info['width'], video_info['height']))\n",
    "\n",
    "# Khởi tạo HOG descriptor/person detector. Mất rất nhiều power cho quá trình này.\n",
    "if dict['pedestrian_detection']:\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    # Sử dụng Background subtraction tách cảnh nền.\n",
    "if dict['motion_detection']:\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(history=300, varThreshold=16, detectShadows=True)\n",
    "\n",
    "# Đọc file yaml (parking space polygons)\n",
    "with open(fn_yaml, 'r') as stream:\n",
    "    parking_data = yaml.load(stream)\n",
    "parking_contours = []\n",
    "parking_bounding_rects = []\n",
    "parking_mask = []\n",
    "parking_data_motion = []\n",
    "if parking_data != None:\n",
    "    for park in parking_data:\n",
    "        points = np.array(park['points'])\n",
    "        rect = cv2.boundingRect(points)\n",
    "        points_shifted = points.copy()\n",
    "        points_shifted[:,0] = points[:,0] - rect[0] # shift contour to region of interest\n",
    "        points_shifted[:,1] = points[:,1] - rect[1]\n",
    "        parking_contours.append(points)\n",
    "        parking_bounding_rects.append(rect)\n",
    "        mask = cv2.drawContours(np.zeros((rect[3], rect[2]), dtype=np.uint8), [points_shifted], contourIdx=-1,\n",
    "                                    color=255, thickness=-1, lineType=cv2.LINE_8)\n",
    "        mask = mask==255\n",
    "        parking_mask.append(mask)\n",
    "\n",
    "kernel_erode = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)) # morphological kernel\n",
    "kernel_dilate = cv2.getStructuringElement(cv2.MORPH_RECT,(5,19))\n",
    "if parking_data != None:\n",
    "    parking_status = [False]*len(parking_data)\n",
    "    parking_buffer = [None]*len(parking_data)\n",
    "\n",
    "def print_parkIDs(park, coor_points, frame_rev):\n",
    "    moments = cv2.moments(coor_points)\n",
    "    centroid = (int(moments['m10']/moments['m00'])-3, int(moments['m01']/moments['m00'])+3)\n",
    "    # Gắn số vào các region được marked bằng tay\n",
    "    cv2.putText(frame_rev, str(park['id']), (centroid[0]+1, centroid[1]+1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame_rev, str(park['id']), (centroid[0]-1, centroid[1]-1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame_rev, str(park['id']), (centroid[0]+1, centroid[1]-1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame_rev, str(park['id']), (centroid[0]-1, centroid[1]+1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame_rev, str(park['id']), centroid, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    current_count = 0\n",
    "    video_cur_pos = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0 # Vị trí hiện tại của video file tính theo giây\n",
    "    video_cur_frame = cap.get(cv2.CAP_PROP_POS_FRAMES) # Vị trí tính theo frame\n",
    "    ret, frame_initial = cap.read()\n",
    "    if ret == True:\n",
    "        frame = cv2.resize(frame_initial, None, fx=0.6, fy=0.6)\n",
    "    if ret == False:\n",
    "        print(\"Video ended\")\n",
    "        break\n",
    "\n",
    "    # Background Subtraction\n",
    "    frame_blur = cv2.GaussianBlur(frame.copy(), (5,5), 3)\n",
    "    frame_gray = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2GRAY)\n",
    "    frame_out = frame.copy()\n",
    "\n",
    "    # Hiển thị số frame trên góc trái video\n",
    "    if dict['text_overlay']:\n",
    "        str_on_frame = \"%d/%d\" % (video_cur_frame, video_info['num_of_frames'])\n",
    "        cv2.putText(frame_out, str_on_frame, (5,30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.8, (0,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame_out,global_str + str(round(change_pos,2)) + 'sec', (5, 60), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.8, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # motion detection cho mọi objects\n",
    "    if dict['motion_detection']:\n",
    "        fgmask = fgbg.apply(frame_blur)\n",
    "        bw = np.uint8(fgmask==255)*255\n",
    "        bw = cv2.erode(bw, kernel_erode, iterations=1)\n",
    "        bw = cv2.dilate(bw, kernel_dilate, iterations=1)\n",
    "        (_, cnts, _) = cv2.findContours(bw.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # Áp loop cho contours\n",
    "        for c in cnts:\n",
    "            # Nếu contours quá nhỏ thì bỏ qua\n",
    "            if cv2.contourArea(c) < dict['min_area_motion_contour']:\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame_out, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
    "\n",
    "    # Detect xe và chỗ trống\n",
    "    if dict['parking_detection']:\n",
    "        for ind, park in enumerate(parking_data):\n",
    "            points = np.array(park['points'])\n",
    "            rect = parking_bounding_rects[ind]\n",
    "            roi_gray = frame_gray[rect[1]:(rect[1]+rect[3]), rect[0]:(rect[0]+rect[2])] # crop ROI để tính toán nhanh hơn\n",
    "\n",
    "            laplacian = cv2.Laplacian(roi_gray, cv2.CV_64F)\n",
    "            points[:,0] = points[:,0] - rect[0] # Chuyển contour sang ROI\n",
    "            points[:,1] = points[:,1] - rect[1]\n",
    "            delta = np.mean(np.abs(laplacian * parking_mask[ind]))\n",
    "            status = delta < dict['park_laplacian_th']\n",
    "            # Nếu phát hiện có sự thay đổi thì lưu thời gian lại\n",
    "            if status != parking_status[ind] and parking_buffer[ind]==None:\n",
    "                parking_buffer[ind] = video_cur_pos\n",
    "                change_pos = video_cur_pos\n",
    "    \n",
    "            # Nếu trạng thái vẫn khác với cái đã được lưu và counter đang open\n",
    "            elif status != parking_status[ind] and parking_buffer[ind]!=None:\n",
    "                if video_cur_pos - parking_buffer[ind] > dict['park_sec_to_wait']:\n",
    "                    parking_status[ind] = status\n",
    "                    parking_buffer[ind] = None\n",
    "            # Nếu trạng thái vẫn như vậy và counter đang open\n",
    "            elif status == parking_status[ind] and parking_buffer[ind]!=None:\n",
    "                parking_buffer[ind] = None\n",
    "\n",
    "    # Thay đổi màu và trạng thái hiển thị trên section phía trên \n",
    "    if dict['parking_overlay']:\n",
    "        for ind, park in enumerate(parking_data):\n",
    "            points = np.array(park['points'])\n",
    "            if parking_status[ind]:\n",
    "                color = (0,255,0)\n",
    "                rect = parking_bounding_rects[ind]\n",
    "                roi_gray_ov = frame_gray[rect[1]:(rect[1] + rect[3]),\n",
    "                               rect[0]:(rect[0] + rect[2])]  # crop ROI để tính toán nhanh hơn\n",
    "                res = run_classifier(roi_gray_ov, ind)\n",
    "                current_count += 1\n",
    "                if res:\n",
    "                    parking_data_motion.append(parking_data[ind])\n",
    "                    color = (0,0,255)\n",
    "            else:\n",
    "                color = (0,0,255)\n",
    "                \n",
    "            \n",
    "            cv2.drawContours(frame_out, [points], contourIdx=-1,\n",
    "                                 color=color, thickness=2, lineType=cv2.LINE_8)\n",
    "            \n",
    "            if dict['show_ids']:\n",
    "                    print_parkIDs(park, points, frame_out)\n",
    "        #Hiển thị số lot trống trong frame\n",
    "        cv2.putText(frame_out,'Total vacant spots in frame: ' + str(current_count),(7,85),cv2.FONT_HERSHEY_SIMPLEX,0.728,(98,189,184),2,cv2.LINE_AA)\n",
    "    \n",
    "    if dict['print_out']:\n",
    "        count=current_count\n",
    "        file = open(\"test.txt\", \"w\") \n",
    "        file.write(str(count)) \n",
    "        file.close() \n",
    "        \n",
    "    if parking_data_motion != []:\n",
    "        for index, park_coord in enumerate(parking_data_motion):\n",
    "            points = np.array(park_coord['points'])\n",
    "            color = (0, 0, 255)\n",
    "            recta = parking_bounding_rects[ind]\n",
    "            roi_gray1 = frame_gray[recta[1]:(recta[1] + recta[3]),\n",
    "                            recta[0]:(recta[0] + recta[2])]  # crop ROI để tính toán nhanh hơn\n",
    "            fgbg1 = cv2.createBackgroundSubtractorMOG2(history=300, varThreshold=16, detectShadows=True)\n",
    "            roi_gray1_blur = cv2.GaussianBlur(roi_gray1.copy(), (5, 5), 3)\n",
    "            fgmask1 = fgbg1.apply(roi_gray1_blur)\n",
    "            bw1 = np.uint8(fgmask1 == 255) * 255\n",
    "            bw1 = cv2.erode(bw1, kernel_erode, iterations=1)\n",
    "            bw1 = cv2.dilate(bw1, kernel_dilate, iterations=1)\n",
    "            (_, cnts1, _) = cv2.findContours(bw1.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # Áp loop cho contours\n",
    "            for c in cnts1:\n",
    "                print(cv2.contourArea(c))\n",
    "                # Nếu contours quá nhỏ thì bỏ qua\n",
    "                if cv2.contourArea(c) < 4:\n",
    "                    continue\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                classifier_result1 = run_classifier(roi_gray1, index)\n",
    "                if classifier_result1:\n",
    "                    color = (0, 0, 255)  # Đỏ nếu có xe\n",
    "                else:\n",
    "                    color = (0,255, 0)\n",
    "            classifier_result1 = run_classifier(roi_gray1, index)\n",
    "            if classifier_result1:\n",
    "                color = (0, 0, 255)  # Đỏ nếu có xe\n",
    "            else:\n",
    "                color = (0, 255, 0)\n",
    "            #cv2.drawContours(frame_out, [points], contourIdx=-1, color=color, thickness=2, lineType=cv2.LINE_8)\n",
    "           \n",
    "    if dict['pedestrian_detection']:\n",
    "        # Detecr người trong video, sẽ làm giản tốc độ chương trình vì cần một GPU có tốc độ xử lý cao\n",
    "        (rects, weights) = hog.detectMultiScale(frame, winStride=(4, 4), padding=(8, 8), scale=1.05)\n",
    "        # Vẽ bounding box\n",
    "        for (x, y, w, h) in rects:\n",
    "            cv2.rectangle(frame_out, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # write output frames\n",
    "    if dict['save_video']:\n",
    "            out.write(frame_out)\n",
    "\n",
    "    # Hiển thị video\n",
    "    cv2.imshow('frame', frame_out)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "    elif k == ord('c'):\n",
    "        cv2.imwrite('frame%d.jpg' % video_cur_frame, frame_out)\n",
    "    elif k == ord('j'):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, video_cur_frame+1000) # Nhảy 1000 frames\n",
    "    elif k == ord('u'):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, video_cur_frame + 50)  # Nhảy 500 frames\n",
    "    if cv2.waitKey(33) == 27:\n",
    "        break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cap.release()\n",
    "if dict['save_video']: out.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution finished\n"
     ]
    }
   ],
   "source": [
    "# Classifier demonstration on M6 highway Britain:\n",
    "import cv2\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "def perform_classification(video_src, cascade_src):\n",
    "    cap = cv2.VideoCapture(video_src)\n",
    "    car_cascade = cv2.CascadeClassifier(cascade_src)\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if (type(img) == type(None)):\n",
    "            print('Video not found')\n",
    "            break\n",
    "        image_scaled = cv2.resize(img, None, fx=0.6, fy=0.6)\n",
    "        gray = cv2.cvtColor(image_scaled, cv2.COLOR_BGR2GRAY)\n",
    "        cars = car_cascade.detectMultiScale(gray, 1.1, 1) #1.1, 1\n",
    "        cars = np.array([[x, y, x + w, y + h] for (x, y, w, h) in cars])\n",
    "        pick = non_max_suppression(cars, probs=None, overlapThresh=0.65)\n",
    "        for (x, y, w, h) in pick:\n",
    "            cv2.rectangle(image_scaled, (x, y), (w,  h), (0, 255, 255), 2)\n",
    "        cv2.imshow('Press ESC key to finish', image_scaled)\n",
    "\n",
    "            # Nhấn Esc để thoát\n",
    "        if cv2.waitKey(33) == 27:\n",
    "            break\n",
    "    print('Execution finished')\n",
    "    cv2.destroyAllWindows()\n",
    "perform_classification('myCam.avi', 'cars.xml')    # M6 highway Britain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 vehicles found\n",
      "95 vehicles found\n",
      "111 vehicles found\n",
      "89 vehicles found\n",
      "104 vehicles found\n",
      "Accuracy after evaluating 5 frames and assuming correct identification:  62.25744531477015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62.25744531477015"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tính toán độ chính xác của classifier. Frames được lấy từ các buổi trong ngày với điều kiện ánh sáng khác sau (sáng chiều tối)\n",
    "import phong_utility_01 as util\n",
    "util.get_acc('phong_classifier.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhấn Esc để hoàn thành việc xác định real time boxing\n",
    "# Chương trình sẽ vẽ những hình tứ giác khi có đủ 4 lần nháy đúp chuột trái\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "refPt = []\n",
    "cropping = False\n",
    "data = []\n",
    "file_path = 'phong_yml_02.yml'\n",
    "img = cv2.imread('phong_frame_02.png')\n",
    "\n",
    "def yaml_loader(file_path):\n",
    "    with open(file_path, \"r\") as file_descr:\n",
    "        data = yaml.load(file_descr)\n",
    "        return data\n",
    "\n",
    "\n",
    "def yaml_dump(file_path, data):\n",
    "    with open(file_path, \"a\") as file_descr:\n",
    "        yaml.dump(data, file_descr)\n",
    "\n",
    "\n",
    "def yaml_dump_write(file_path, data):\n",
    "    with open(file_path, \"w\") as file_descr:\n",
    "        yaml.dump(data, file_descr)\n",
    "\n",
    "\n",
    "def click_and_crop(event, x, y, flags, param):\n",
    "    current_pt = {'id': 0, 'points': []}\n",
    "    # grab references cho biến global\n",
    "    global refPt, cropping\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        refPt.append((x, y))\n",
    "        cropping = False\n",
    "    if len(refPt) == 4:\n",
    "        if data == []:\n",
    "            if yaml_loader(file_path) != None:\n",
    "                data_already = len(yaml_loader(file_path))\n",
    "            else:\n",
    "                data_already = 0\n",
    "        else:\n",
    "            if yaml_loader(file_path) != None:\n",
    "                data_already = len(data) + len(yaml_loader(file_path))\n",
    "            else:\n",
    "                data_already = len(data) \n",
    "        \n",
    "        cv2.line(image, refPt[0], refPt[1], (0, 255, 0), 1)\n",
    "        cv2.line(image, refPt[1], refPt[2], (0, 255, 0), 1)\n",
    "        cv2.line(image, refPt[2], refPt[3], (0, 255, 0), 1)\n",
    "        cv2.line(image, refPt[3], refPt[0], (0, 255, 0), 1)\n",
    "\n",
    "        temp_lst1 = list(refPt[2])\n",
    "        temp_lst2 = list(refPt[3])\n",
    "        temp_lst3 = list(refPt[0])\n",
    "        temp_lst4 = list(refPt[1])\n",
    "\n",
    "        current_pt['points'] = [temp_lst1, temp_lst2, temp_lst3, temp_lst4]\n",
    "        current_pt['id'] = data_already\n",
    "        data.append(current_pt)\n",
    "        refPt = []\n",
    "image = cv2.resize(img, None, fx=0.6, fy=0.6)\n",
    "clone = image.copy()\n",
    "cv2.namedWindow(\"Double click to mark points\")\n",
    "cv2.imshow(\"Double click to mark points\", image)\n",
    "cv2.setMouseCallback(\"Double click to mark points\", click_and_crop)\n",
    "\n",
    "# Tiếp tục looping cho đến khi 'q' được nhấn\n",
    "while True:\n",
    "    # Hiển thị hình ảnh cho đến khi được được nhấn\n",
    "    cv2.imshow(\"Double click to mark points\", image)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if cv2.waitKey(33) == 27:\n",
    "        break\n",
    "       \n",
    "# data list vào yaml file\n",
    "if data != []:\n",
    "    yaml_dump(file_path, data)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-66529c9b6fef>:15: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  parking_data = yaml.load(stream)\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "no median for empty data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-66529c9b6fef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum_up\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparking_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mmed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mean: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"median: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python38-32\\lib\\statistics.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no median for empty data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStatisticsError\u001b[0m: no median for empty data"
     ]
    }
   ],
   "source": [
    "# Chương trình tính toán giá trị Threshold cho một parking area có sẵn\n",
    "import statistics\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "        \n",
    "sum_up = 0.0\n",
    "delta_list = []\n",
    "frame = cv2.imread('123.png') #\n",
    "parking_bounding_rects = []\n",
    "parking_mask = []\n",
    "frame_blur = cv2.GaussianBlur(frame.copy(), (5,5), 3)\n",
    "frame_gray = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2GRAY)\n",
    "with open('phong_yml_01.yml', 'r') as stream:\n",
    "    parking_data = yaml.load(stream)\n",
    "    \n",
    "if parking_data != None:\n",
    "    for park in parking_data:\n",
    "        points = np.array(park['points'])\n",
    "        rect = cv2.boundingRect(points)\n",
    "        points_shifted = points.copy()\n",
    "        points_shifted[:,0] = points[:,0] - rect[0] # shift contour to region of interest\n",
    "        points_shifted[:,1] = points[:,1] - rect[1]\n",
    "        \n",
    "        parking_bounding_rects.append(rect)\n",
    "        mask = cv2.drawContours(np.zeros((rect[3], rect[2]), dtype=np.uint8), [points_shifted], contourIdx=-1,\n",
    "                                    color=255, thickness=-1, lineType=cv2.LINE_8)\n",
    "        mask = mask==255\n",
    "        parking_mask.append(mask)\n",
    "\n",
    "for ind, park in enumerate(parking_data):\n",
    "        points = np.array(park['points'])\n",
    "        rect = parking_bounding_rects[ind]\n",
    "        roi_gray = frame_gray[rect[1]:(rect[1]+rect[3]), rect[0]:(rect[0]+rect[2])] # crop ROI để tính toán nhanh hơn\n",
    "\n",
    "        laplacian = cv2.Laplacian(roi_gray, cv2.CV_64F)\n",
    "        points[:,0] = points[:,0] - rect[0] # shift contour to roi\n",
    "        points[:,1] = points[:,1] - rect[1]\n",
    "        delta = np.mean(np.abs(laplacian * parking_mask[ind]))\n",
    "        if(delta > 1.8):    # Bỏ qua space trống\n",
    "            delta_list.append(delta)\n",
    "        sum_up = sum_up + delta\n",
    "        \n",
    "avg = sum_up/len(parking_data)\n",
    "med = statistics.median(delta_list)\n",
    "print(\"mean: \", avg)\n",
    "print(\"median: \", med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết luận\n",
    "Hệ thống đề xuất một phương pháp hiệu quả để quản lý hệ thống bãi đậu xe bằng cách sử dụng máy ảnh được đặt ở các cột đèn. Độ chính xác của hệ thống phụ thuộc vào giá trị Threshold, thuật toán theo dõi chuyển động dựa trên background subtraction và quan trọng nhất là sức mạnh của classifier. Thách thức phải đối mặt là để xác định chuyển động trong một ROI nhỏ khi có tồn tại khả năng có nhiễu. Ví dụ, máy ảnh được đặt gần cầu thang và reflection của những người đi bộ xuống cầu thang đã được reflect trong video đầu vào được cung cấp bởi máy ảnh. Nó trở nên khó khăn để giảm tác động của nhiễu và phát hiện được các chuyển động nhỏ. Bên cạnh đó, Haar classifier đã thực hiện tốt mục tiêu đặt ra của đề tài nhưng thực hiện classifier dựa trên Convolution Neural Networks sẽ làm tăng độ chính xác tổng thể của hệ thống một cách đáng kể. Đây là phạm vi công việc trong tương lai của dự án này. Tuy nhiên với hiện tại thì mức độ chính xác của hệ thống là rất tốt với độ chính xác hơn 85% với mô hình bãi đỗ xe vừa-nhỏ và hơn 62.5% với mô hình bãi độ xe lớn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tham khảo\n",
    "\n",
    "### 1. Video \n",
    "-https://www.youtube.com/watch?v=bPeGC8-PQJg\n",
    "\n",
    "-https://www.youtube.com/watch?v=Dg-4MoABv4I\n",
    "\n",
    "\n",
    "### 2. Codes\n",
    "-https://github.com/eladj/detectParking\n",
    "\n",
    "-http://www.pyimagesearch.com/2015/11/09/pedestrian-detection-opencv/\n",
    "\n",
    "### 3. Papers\n",
    "[1] M. I. et al, “Car park system: A review of smart parking system and its technology,” Information Technology Journal, 2009.\n",
    "In this study, various types of smart parking systems with their pros and cons are presented.\n",
    "\n",
    "[2] N. True, “Vacant parking space detection in static images,” 2007. http://cseweb.ucsd.edu/classes/wi07/cse190-a/reports/ntrue.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
